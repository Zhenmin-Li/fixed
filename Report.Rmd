---
title: "Project Report"
output: pdf_document
---

We analyze the Netflix dataset.

```{r, warning=F, message=F, echo=F}
netflix <- read.csv("derived_data/netflix.csv")
movies <- read.csv("derived_data/movies.csv")
tv <- read.csv("derived_data/tv.csv")

#head(netflix)
```

This can be done best by breaking it up into the TV and movies datasets separately.

With the data on TV shows, we're interested in possibly predicting the number of seasons from the other variables. Some of these variables are highly unlikely to overfit. For example, title, director, cast, and description all possibly uniquely identify the TV show. The useful predictor variables here appear to be country, release year, and listed in and/or rating. Let's fit a simple linear regression model and see how well it predicts the number of seasons from those 4 variables:

```{r, warning=F, message=F, echo=F}
# summary(readRDS("derived_data/naive_linear_model.rds"));
# m <- lm(num_seasons ~ country + release_year + rating + listed_in, 
#         data = tv)
# summary(m)
length(unique(tv$country)) * length(unique(tv$rating)) * length(unique(tv$listed_in))
```

This "simple" model just estimated 394,320 parameters because we didn't think about how many different countries and categories of TV there are. Let's try a much simpler model that takes only rating and release year into account:

```{r, warning=F, message=F, echo=F}
summary(readRDS("derived_data/linear_model1.rds"))
```

Interestingly, this model seems to suggest that rating is NOT a significant predictor for number of seasons. So, we will exclude it from the model, and instead examine by only release year.

```{r, warning=F, message=F, echo=F}
summary(readRDS("derived_data/linear_model2.rds"))
```

![]("derived_data/model2_plot1.png")
![]("derived_data/model2_plot2.png")

This (clearly) does not satisfy the assumptions of linear regression that have to do with the error terms being normally distributed with mean zero and constant variance. Let's see if we can get a better fit by using a LOESS model.

```{r, warning=F, message=F, echo=F}
summary(readRDS("derived_data/loess_model3.rds"))
```

![]("derived_data/model3_image1.png")
![]("derived_data/model3_image2.png")

The model seems to be completely dominated by a majority of TV shows with few seasons. How many shows run for only 1 season?

It appears that the vast majority of shows on Netflix run for 1 season. 

# Future Directions

This analysis is not super interesting. In the future, I would maybe try to learn some simple text analysis and/or try to merge this data with movie/tv ratings to see whether I can predict them.
